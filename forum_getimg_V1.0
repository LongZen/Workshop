# -*- coding: utf-8 -*-
"""
Created on Tue Aug  8 20:05:03 2017

@author: Michael
"""

#这是一个简单的网络爬虫程序
#首先，引入我们需要用到的模块
import requests
from bs4 import BeautifulSoup
import os
import re

headers = {'User-Agent':"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1"}
##浏览器请求头（大部分网站没有这个请求头会报错、请务必加上哦）

url='http://www.tuyimm.com/forum-12-1.html' ##要爬取的URL地址

html=requests.get(url,headers=headers)   
##使用requests中的get方法来获取url()的内容 headers为上面设置的请求头、请务必参考requests官方文档解释

#print(html.text)##打印出html的文本内容。注意：用于打印网页。其它如图片、视频、音频等多媒体的下载用content。

Soup=BeautifulSoup(html.text,'lxml')#用BS解析网页内容，‘lxml’是指定的解析器。

#使用Soup解析网页后就可以找标签了。findall是查找所有标签内容的意思，返回的是一个列表
a_tag=Soup.find_all('a',class_='preview') #找到jpg图片所在标签下的所有列表，也就是套图的入口地址


import urllib
from urllib.request import urlopen,urlretrieve

#定义要提取的图片地址格式，并进行编译
reg = r'zoomfile="(.+?\.jpg)" '
imgre = re.compile(reg)

#从第一个<a>标签地址开始遍历
i = 0
for a in a_tag:
    title=a['title'] #取出a标签的title属性
    path=str(title)  #转换成字符串格式
    
    #这个模块用title命名，新建并打开文件夹
    isExists = os.path.exists(os.path.join("E:\pic", path))
    if not isExists:
        print(u'建了一个名字叫做', path, u'的文件夹！')
        os.makedirs(os.path.join("E:\pic", path))
    else:
        print(u'名字叫做', path, u'的文件夹已经存在了！')
    os.chdir("E:\pic\\"+path)
    
    href=a['href'] #取出a标签的href属性； #print(title,href)，打开来看一下title与href是否匹配
    print(href) #打印套图入口地址；  #all_url=href[:] #入口地址都在href[:]
    
    #读取套图入口地址并转换成字符串格式
    page = urlopen(href)
    html = str(page.read())
    page.close()
    
    #从入口地址中找到所有图片地址列表
    imglist = re.findall(imgre,html)
    x = 0
    for imgurl in imglist:
        #print(imgurl)
        img=requests.get(imgurl)   #提取图片路径
        name='%s-%s.jpg' %(i,x)    #给图片命名
        f=open(name,'ab')          #打开图片文件
        f.write(img.content)       #写入图片
        f.close()                  #这个模块定义了逐个保存图片的方法
        x = x + 1
        print('Done')
    print('第'+str(i)+'套 Done')
    i = i + 1
    
print("All Done!")
    

    


    
